{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIN-393 - Introdução à Visão Computacional (2022-2)**\n",
    "\n",
    "# Projeto Classificação de Imagens\n",
    "\n",
    "Nome: Caio da Silva de Miranda\n",
    "\n",
    "Matrícula: 6368\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from skimage import util, transform, filters, color, measure, morphology\n",
    "from sklearn import model_selection, neighbors, metrics, preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "np.random.seed(393)\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o conjunto de dados do projeto\n",
    "---\n",
    "* Vamos utilizar um conjunto de dados fornecido pelo professor contendo:\n",
    "* 4 Classes:\n",
    "    * 0 apple;\n",
    "    * 1 bat;\n",
    "    * 2 beetle;\n",
    "    * 3 bone;\n",
    "* 720 objetos:   \n",
    "    * 180 objetos de cada classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Datasets necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cada conjunto possui 4 classes (apple, bat, beetle, bone)\n",
    "datasetTeste = 'datasets/Test'\n",
    "\n",
    "datasetTreino = 'datasets/Train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checagem para saber se os datasets foram recebidos corretamente\n",
    "print(datasetTeste)\n",
    "\n",
    "print(datasetTreino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando as imagens de ambos Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista das pastas na pasta 'Train' (classes)\n",
    "classes_list = os.listdir(datasetTreino)\n",
    "\n",
    "# Lista com as imagens no dataset\n",
    "image_list = []\n",
    "# Lista com os rótulos das imagens\n",
    "label_list = []\n",
    "\n",
    "# Lista com os nomes das imagens\n",
    "filename_list_ = []\n",
    "\n",
    "# Percorre as classes do dataset\n",
    "for classe in classes_list:\n",
    "    \n",
    "    # Listagem de todas as imagens na pasta daquela classe\n",
    "    filename_list = os.listdir(os.path.join(datasetTreino, classe))\n",
    "    \n",
    "    # Percorre os arquivos na pasta atual\n",
    "    for filename in filename_list:\n",
    "        # Carrega a imagem\n",
    "        img_temp = io.imread(os.path.join(datasetTreino, classe, filename))\n",
    "        \n",
    "        # Adiciona a imagem a lista de imagens\n",
    "        image_list.append(img_temp)\n",
    "        \n",
    "        # Adiciona o rótulo da imagem à lista de rótulos\n",
    "        label_list.append(classe)\n",
    "        \n",
    "        # Adiciona o nome da imagem à uma lista (para fins de visualização)\n",
    "        filename_list_.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com os rótulos (classes) das imagens        \n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista das pastas na pasta 'Test' (classes)\n",
    "classes_list2 = os.listdir(datasetTeste)\n",
    "\n",
    "# Lista com as imagens no dataset\n",
    "image_list2 = []\n",
    "# Lista com os rótulos das imagens\n",
    "label_list2 = []\n",
    "\n",
    "# Lista com os nomes das imagens\n",
    "filename_list_2 = []\n",
    "\n",
    "# Percorre as classes do dataset\n",
    "for classe in classes_list2:\n",
    "    \n",
    "    # Listagem de todas as imagens na pasta daquela classe\n",
    "    filename_list2 = os.listdir(os.path.join(datasetTeste, classe))\n",
    "    \n",
    "    # Percorre os arquivos na pasta atual\n",
    "    for filename in filename_list2:\n",
    "        # Carrega a imagem\n",
    "        img_temp = io.imread(os.path.join(datasetTeste, classe, filename))\n",
    "        \n",
    "        # Adiciona a imagem a lista de imagens\n",
    "        image_list2.append(img_temp)\n",
    "        \n",
    "        # Adiciona o rótulo da imagem à lista de rótulos\n",
    "        label_list2.append(classe)\n",
    "        \n",
    "        # Adiciona o nome da imagem à uma lista (para fins de visualização)\n",
    "        filename_list_2.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com os rótulos das imagens        \n",
    "print(label_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertendo os nomes das classes para índices numéricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices das classes dos objetos do dataset\n",
    "_, _, label_list_idx = np.unique(label_list, return_index=True, return_inverse=True)\n",
    "\n",
    "print(type(label_list_idx))\n",
    "print(label_list_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices das classes dos objetos do dataset\n",
    "_, _, label_list_idx2 = np.unique(label_list2, return_index=True, return_inverse=True)\n",
    "\n",
    "print(type(label_list_idx2))\n",
    "print(label_list_idx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo algumas caracteristicas das imagens\n",
    "----\n",
    "* Vamos extrair algumas caracteristicas de forma dos objetos nas imagens.\n",
    "    * Área, maior eixo, menor eixo e solidez.\n",
    "* Primeiramente precisamos criar um vetor que receberá as características.\n",
    "* Também será necessário criar um contador para sabermos quantas imagens tiveram problemas durante o processo de extração, e mais à frente calcularmos a diferença que cada classe teve, ou seja, identificar o numero total de imagens bem sucedidas e que servirão para a procedência do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo do Dataset Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes das caracteristicas computadas\n",
    "features = ['area', 'major_axis', 'minor_axis', 'solidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranjo 2D com as caracteristicas das imagens\n",
    "#   Cada linha armazena informações sobre uma imagem. Cada coluna armazena uma caracteristica.\n",
    "#   [ [area, major_axis, minor_axis, solidity] ]\n",
    "feature_mat = []\n",
    "\n",
    "# Lista com as imagens segmentadas (binárias)\n",
    "seg_list = []\n",
    "\n",
    "# Lista com os rótulos das imagens\n",
    "list_label = []\n",
    "\n",
    "#Contador de imagens que obtiveram problemas durante extração de características\n",
    "errorcount = []\n",
    "\n",
    "for i, (image, label) in enumerate(zip(image_list, label_list)):\n",
    "    # DEBUG\n",
    "    print('Imagem {} - classe {}'.format(i, label))\n",
    "    \n",
    "    # Adiciona o rótulos (label) da imagem à lista\n",
    "    list_label.append(label)\n",
    "    \n",
    "    # Calcula uma lista de propriedades (características) dos objetos na imagem\n",
    "    props = measure.regionprops(image.astype(int))\n",
    "    \n",
    "    ###print(len(props))\n",
    "    if len(props) != 1:\n",
    "        \n",
    "        errorcount.append((i,label))\n",
    "        print(f'ERRO de segmentação: {len(props)}')\n",
    "        continue\n",
    "\n",
    "    # Itera pelas propriedades computadas\n",
    "    for prop in props:\n",
    "        # Prop. 0: Area\n",
    "        area = prop.area\n",
    "       \n",
    "        # Prop. 1: Maior eixo\n",
    "        major_axis = prop.major_axis_length\n",
    "        \n",
    "        # Prop. 2: Menor eixo\n",
    "        minor_axis = prop.minor_axis_length \n",
    "        \n",
    "        # Prop. 3: Solidez\n",
    "        solidity = prop.solidity \n",
    "\n",
    "        # Monta o vetor de caracteristicas deste objeto.\n",
    "        feature_list = [area, major_axis, minor_axis, solidity]\n",
    "    \n",
    "    # Adiciona as caracteristicas desta imagem na matriz de caracteristicas\n",
    "    feature_mat.append(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibindo imagens mal sucedidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(errorcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converte a lista de caracteristicas para um arranjo NumPy\n",
    "feature_map = np.array(feature_mat)\n",
    "\n",
    "# Imprime a matriz de caracteristica\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas estatisticas sobre o conjunto de caracteristicas\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(feature_map.min(0))\n",
    "    print(feature_map.max(0))\n",
    "    print(feature_map.mean(0))\n",
    "    print(feature_map.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo do Dataset Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes das caracteristicas computadas\n",
    "features2 = ['area2', 'major_axis2', 'minor_axis2', 'solidity2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranjo 2D com as caracteristicas das imagens\n",
    "#   Cada linha armazena informações sobre uma imagem. Cada coluna armazena uma caracteristica.\n",
    "#   [ [area, major_axis, minor_axis, solidity] ]\n",
    "feature_mat2 = []\n",
    "\n",
    "# Lista com as imagens segmentadas (binárias)\n",
    "seg_list2 = []\n",
    "\n",
    "# Lista com os rótulos das imagens\n",
    "list_label2 = []\n",
    "\n",
    "#Contador de erros\n",
    "errorcount2 = []\n",
    "\n",
    "for i2, (image2, label2) in enumerate(zip(image_list2, label_list2)):\n",
    "    # DEBUG\n",
    "    print('Imagem {} - classe {}'.format(i2, label2))\n",
    "    \n",
    "    # Adiciona o rótulos (label) da imagem à lista\n",
    "    list_label2.append(label2)\n",
    "    \n",
    "    # Calcula uma lista de propriedades (características) dos objetos na imagem\n",
    "    props2 = measure.regionprops(image2.astype(int))\n",
    "    \n",
    "    ###print(len(props))\n",
    "    if len(props2) != 1:\n",
    "        \n",
    "        errorcount2.append((i2,label2))\n",
    "        print(f'ERRO de segmentação: {len(props2)}')\n",
    "        continue\n",
    "\n",
    "    # Itera pelas propriedades computadas\n",
    "    for prop2 in props2:\n",
    "        # Prop. 0: Area\n",
    "        area2 = prop2.area\n",
    "       \n",
    "        # Prop. 1: Maior eixo\n",
    "        major_axis2 = prop2.major_axis_length\n",
    "        \n",
    "        # Prop. 2: Menor eixo\n",
    "        minor_axis2 = prop2.minor_axis_length \n",
    "        \n",
    "        # Prop. 3: Solidez\n",
    "        solidity2 = prop2.solidity \n",
    "\n",
    "        # Monta o vetor de caracteristicas deste objeto.\n",
    "        feature_list2 = [area2, major_axis2, minor_axis2, solidity2]\n",
    "    \n",
    "    # Adiciona as caracteristicas desta imagem na matriz de caracteristicas\n",
    "    feature_mat2.append(feature_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibindo imagens mal sucedidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(errorcount2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converte a lista de caracteristicas para um arranjo NumPy\n",
    "feature_map2 = np.array(feature_mat2)\n",
    "\n",
    "# Imprime a matriz de caracteristica\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(feature_map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas estatisticas sobre o conjunto de caracteristicas\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(feature_map2.min(0))\n",
    "    print(feature_map2.max(0))\n",
    "    print(feature_map2.mean(0))\n",
    "    print(feature_map2.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando os dados para serem computados\n",
    "---\n",
    "\n",
    "* Aqui estamos calculando a diferença para cada classe do dataset completo, pelas imagens que não passaram do processo de extração, caso alguma tenha problema durante o processo de segmentação. Foi notado que uma grande quantidade de imagens tinham tido problemas durante o processo de extração devido ao tipo de imagem (*float != int*) e foi corrigido na  função measure.regioprops com um método simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_apple = 0\n",
    "cont_beetle = 0\n",
    "cont_bat = 0\n",
    "cont_bone = 0\n",
    "\n",
    "for num, classe in errorcount:\n",
    "    if classe == 'apple':\n",
    "        cont_apple = cont_apple + 1\n",
    "    if classe == 'beetle':\n",
    "        cont_beetle = cont_beetle + 1\n",
    "    if classe == 'bat':\n",
    "        cont_bat = cont_bat + 1\n",
    "    if classe == 'bone':\n",
    "        cont_bone = cont_bone + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels_treino = list()\n",
    "for i in range(126 - cont_apple):\n",
    "    list_labels_treino.append('apple')\n",
    "for i in range(126 - cont_beetle):\n",
    "    list_labels_treino.append('beetle')\n",
    "for i in range(126 - cont_bat):\n",
    "    list_labels_treino.append('bat')\n",
    "for i in range(126 - cont_bone):\n",
    "    list_labels_treino.append('bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cont_apple)\n",
    "print(cont_beetle)\n",
    "print(cont_bat)\n",
    "print(cont_bone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_apple = 0\n",
    "cont_beetle = 0\n",
    "cont_bat = 0\n",
    "cont_bone = 0\n",
    "\n",
    "for num, classe in errorcount2:\n",
    "    if classe == 'apple':\n",
    "        cont_apple = cont_apple + 1\n",
    "    if classe == 'beetle':\n",
    "        cont_beetle = cont_beetle + 1\n",
    "    if classe == 'bat':\n",
    "        cont_bat = cont_bat + 1\n",
    "    if classe == 'bone':\n",
    "        cont_bone = cont_bone + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels_teste = list()\n",
    "for i in range(54 - cont_apple):\n",
    "    list_labels_teste.append('apple')\n",
    "for i in range(54 - cont_beetle):\n",
    "    list_labels_teste.append('beetle')\n",
    "for i in range(54 - cont_bat):\n",
    "    list_labels_teste.append('bat')\n",
    "for i in range(54 - cont_bone):\n",
    "    list_labels_teste.append('bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cont_apple)\n",
    "print(cont_beetle)\n",
    "print(cont_bat)\n",
    "print(cont_bone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotando as caracteristicas computadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(feature_map, columns=features)\n",
    "\n",
    "df['class'] = list_labels_treino\n",
    "\n",
    "### print(df)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(df, hue='class', vars=features)\n",
    "g.fig.set_size_inches(8, 8)\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(feature_map2, columns=features2)\n",
    "\n",
    "df['class'] = list_labels_teste\n",
    "\n",
    "### print(df)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(df, hue='class', vars=features2)\n",
    "g.fig.set_size_inches(8, 8)\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando as caracteristicas\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando para dataset Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=4, suppress=True):\n",
    "    # Média das caracteristicas do conjunto de imagens\n",
    "    print('Média:')\n",
    "    print(feature_map.mean(0))\n",
    "    # Desvio padrão das caracteroisticas do conjunto de imagens\n",
    "    print('Desvio padrão:')\n",
    "    print(feature_map.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformada Normal de Caracteristicas\n",
    "feature_map_norm = (feature_map - feature_map.mean(0)) / feature_map.std(0)\n",
    "\n",
    "print(feature_map_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=4, suppress=True):\n",
    "    # Média das caracteristicas do conjunto de imagens\n",
    "    print('Média:')\n",
    "    print(feature_map_norm.mean(0))\n",
    "    # Desvio padrão das caracteroisticas do conjunto de imagens\n",
    "    print('Desvio padrão:')\n",
    "    print(feature_map_norm.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando para dataset Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=4, suppress=True):\n",
    "    # Média das caracteristicas do conjunto de imagens\n",
    "    print('Média:')\n",
    "    print(feature_map2.mean(0))\n",
    "    # Desvio padrão das caracteroisticas do conjunto de imagens\n",
    "    print('Desvio padrão:')\n",
    "    print(feature_map2.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transformada Normal de Caracteristicas\n",
    "feature_map2_norm = (feature_map2 - feature_map2.mean(0)) / feature_map2.std(0)\n",
    "\n",
    "print(feature_map2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=4, suppress=True):\n",
    "    # Média das caracteristicas do conjunto de imagens\n",
    "    print('Média:')\n",
    "    print(feature_map2_norm.mean(0))\n",
    "    # Desvio padrão das caracteroisticas do conjunto de imagens\n",
    "    print('Desvio padrão:')\n",
    "    print(feature_map2_norm.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotando as caracteristicas normalizadas - Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.DataFrame(feature_map_norm, columns=features)\n",
    "\n",
    "df_norm['class'] = list_labels_treino\n",
    "print(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(df_norm, hue='class', vars=features)\n",
    "g.fig.set_size_inches(8, 8)\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotando as caracteristicas normalizadas - Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm2 = pd.DataFrame(feature_map2_norm, columns=features2)\n",
    "\n",
    "df_norm2['class'] = list_labels_teste\n",
    "print(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(df_norm2, hue='class', vars=features2)\n",
    "g.fig.set_size_inches(8, 8)\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada - Hold-out\n",
    "---\n",
    "\n",
    "* Separa o conjunto de dados em subconjuntos para treinamento, validação e testes. \n",
    "    * Neste exemplo, por motivos de simplificação, vamos dividir em treino e testes apenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando apenas duas das 4 características: Área e maior-eixo\n",
    "feature_map_ok = feature_map[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_map\n",
    "X_test = feature_map2\n",
    "y_train = list_labels_treino\n",
    "y_test = list_labels_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando as caracteristicas\n",
    "\n",
    "* A normalização **não** deve ser realizada sobre todo o conjunto de dados. \n",
    "    * A normalização deve ser realizada **após** a divisão do conjunto para a validação cruzada.\n",
    "    * O conjunto de testes não deve ser acessado, nem direta nem indiretamente, durante o treinamento ou durante o ajuste de hiperparâmetros. \n",
    "    * A normalização do conjunto de treinamento e também do conjunto de testes deve ser realizado usando apenas a média e o desvio padrão do conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média das caracteristicas do conjunto de treinamento\n",
    "X_train_mean = X_train.mean(0)\n",
    "# Desvio padrão das caracteristicas do conjunto de treinamento\n",
    "X_train_std = X_train.std(0)\n",
    "\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(X_train.mean(0))\n",
    "    print(X_train.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformada Normal de Caracteristicas\n",
    "X_train_norm = (X_train - X_train_mean) / X_train_std\n",
    "X_test_norm = (X_test - X_train_mean) / X_train_std\n",
    "\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(X_train_norm)\n",
    "    print(X_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificando usando K-vizinhos mais próximos\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrói um classificador do tipo K-NN onde K = 3.\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Treinando o classificador\n",
    "clf.fit(X_train_norm, y_train)\n",
    "\n",
    "# Testando o classificador\n",
    "pred = clf.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação de modelo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predições e acertos utilizando o classificador\n",
    "acertos = y_test == pred\n",
    "\n",
    "print('\\n Predição:')\n",
    "print(pred)\n",
    "print('\\nReal:')\n",
    "print(y_test)\n",
    "print('\\nAcerto/Erro:')\n",
    "print(acertos.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão e o relatório de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nMatriz de confusão:')\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print('\\nRelatório de classificação:')\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizando hiperparametros com o conjunto de validação\n",
    "---\n",
    "* Não se deve realizar a otimização de hiperparâmetros usando o conjunto de testes.\n",
    "* Dessa forma, separamos uma parte do conjunto de treinamento para validação.\n",
    "* Para fazer isso usando o Scikit-learn:\n",
    "    * Primeiro separamos o conjunte do dados total em teste e treino. \n",
    "    * Depois separamos o conjunto de treino em validação e conjunto de testes final. \n",
    "\n",
    "* *Exemplo:* 20% para testes, 20% para validação e 60% para treinamento.\n",
    "\n",
    "```\n",
    " +-- Conjunto de dados - 100%\n",
    "     +-- Conjunto de testes - 20%\n",
    "     +-- Conjunto de treino 1 - 80%\n",
    "         +-- Conjunto de validação - 20% do conjunto de dados = 25% do conjunto de treino 1 (0,2 / 0,8 = 0,25)\n",
    "         +-- Conjunto de treino 2 - 60 % do conjunto de dados = 75% do conjunto de treino 1 (0,8 * 0,75 = 0,6)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Entretanto, o exemplo anterior estava muito fácil de resolver, conseguimos acertar 100% dos casos na primeira tentativa.\n",
    "* Vamos escolher outras caracteristicas, para tornar a tarefa um pouco mais dificil para o nosso classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionamos apenas duas caracteristicas: Área e solidez\n",
    "feature_map_ok = feature_map[:,[0,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos melhorar a divisão do conjutno de dados também;\n",
    "    * Vamsos adotar uma divisão estratificada.\n",
    "        * A divisão estratificada preserva a proporção entre amostras de cada classe nos conjuntos de treino, validação e testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_map_ok\n",
    "X_test = feature_map2[:,[0,3]]\n",
    "y_train = list_labels_treino\n",
    "y_test = list_labels_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa 25% do conjuto de treinamento 1 para validação.\n",
    "#   -> Equivale a 20% do conjunto completo. 0,2 / 0,8 = 0,25\n",
    "X_train_2, X_val, y_train_2, y_val = model_selection.train_test_split(X_train, \n",
    "                                                                      y_train, \n",
    "                                                                      test_size=0.25, \n",
    "                                                                      stratify=y_train,\n",
    "                                                                      random_state=393)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando as características\n",
    "* Obtemos uma estimativa da média e do desvio padrão dos dados a partir do conjunto de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média das caracteristicas do conjunto de treinamento\n",
    "X_train_2_mean = X_train_2.mean(0)\n",
    "\n",
    "# Desvio padrão das caracteristicas do conjunto de treinamento\n",
    "X_train_2_std = X_train_2.std(0)\n",
    "\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(X_train_2.mean(0))\n",
    "    print(X_train_2.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aqui utilizamos a função disponível no Scikit-learn para fazermos a normalização das características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train_2)\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(f'Média:  \\t {np.array(scaler.mean_)}')\n",
    "    print(f'Desv. pad.: \\t {np.array(scaler.scale_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_norm = scaler.transform(X_train_2)\n",
    "X_val_norm = scaler.transform(X_val)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(f'Treino: \\t {X_train_norm.mean():.4f} ± {X_train_norm.std():.4f}')\n",
    "    print(f'Validação: \\t {X_val_norm.mean():.4f} ± {X_val_norm.std():.4f}')\n",
    "    print(f'Teste:   \\t {X_test_norm.mean():.4f} ± {X_test_norm.std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizando o valor de *k*\n",
    "* Vamos encontrar o melhor valor de k para o K-means em termos de acurácia.\n",
    "* Vamos testar os seguintes valores de 'k': 1, 3, 5, 7 e 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [1, 3, 5, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com as acurácias de traino\n",
    "acc_train_list = []\n",
    "# Lista com as acurácias de validação\n",
    "acc_val_list = []\n",
    "\n",
    "for k_ in k_list:\n",
    "    # Constrói um classificador K-NN. K = k_\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=k_)\n",
    "\n",
    "    # Treinando o classificador\n",
    "    clf.fit(X_train_2_norm, y_train_2)\n",
    "\n",
    "    # Testando o classificador (usando o conjunto de validação)\n",
    "    pred = clf.predict(X_val_norm)\n",
    "    acc_val = metrics.accuracy_score(y_val, pred)\n",
    "    \n",
    "    acc_val_list.append(acc_val)\n",
    "    \n",
    "    # Testando o classificador (usando o conjunto de treino)\n",
    "    # **** Apenas para comparar com o resultado da validação ****\n",
    "    pred_train = clf.predict(X_train_2_norm)\n",
    "    acc_train = metrics.accuracy_score(y_train_2, pred_train)\n",
    "    \n",
    "    acc_train_list.append(acc_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(k_list, acc_train_list, 'o', color='blue', label='treino')\n",
    "plt.plot(k_list, acc_val_list, 'x', color='red', label='validação')\n",
    "plt.xlabel(\"Valor de 'k'\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('k \\t acc. treino \\t acc. val')\n",
    "print('----------------------------')\n",
    "for k_, acc_t, acc_v in zip(k_list, acc_train_list, acc_val_list):\n",
    "    print(f'{k_} \\t {acc_t:.4f} \\t {acc_v:.4f}')\n",
    "\n",
    "k_best = k_list[np.argmax(acc_val_list)]\n",
    "print(f'\\nMelhor \\'k\\': {k_best} ({np.max(acc_val_list):.4f} acc.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando melhor *k* encontrado sob conjunto de Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrói um classificador K-NN. K = k_best\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=k_best)\n",
    "\n",
    "# Treinando o classificador\n",
    "clf.fit(X_train_2_norm, y_train_2)\n",
    "\n",
    "# Testando o classificador (usando o conjunto de TESTES)\n",
    "pred = clf.predict(X_test_norm)\n",
    "acc_val = metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Matriz de confusão e relatório de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nMatriz de confusão:')\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print('\\nRelatório de classificação:')\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
